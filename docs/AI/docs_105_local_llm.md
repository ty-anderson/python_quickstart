# Ollama

Ollama is an open-source LLM runtime environment. 

Simply put:

1. Rum Ollama
2. Download the model you'd like to use (mistral, llama3, etc.)
3. Go to the WebUI
4. Select the model you want to use.
5. Chat away!

Download a model: ``docker exec -it ollama ollama pull mistral`` or ``docker exec -it ollama ollama pull llama3``



